{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Watcharachai/Beginner-Code/blob/master/Full_Al_Line_Notice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DybxhttnikgZ"
   },
   "source": [
    "# Import Packages and Produce Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AQEnvFVAikga"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import schedule\n",
    "import pip\n",
    "import stop_words\n",
    "import pythainlp\n",
    "from pythainlp import word_tokenize\n",
    "#from pythainlp.corpus import stopwords\n",
    "from pythainlp.corpus import wordnet\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "from stop_words import get_stop_words\n",
    "import tweepy\n",
    "import random\n",
    "import re\n",
    "import string\n",
    "import stop_words\n",
    "import nltk\n",
    "from pythainlp.corpus import thai_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XrK5Q0isikge"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wflC23JIikgh"
   },
   "source": [
    "# Pull Current Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2-b9-vLFikgi"
   },
   "outputs": [],
   "source": [
    "#Define important words\n",
    "bag_words = ['อุบัติเหตุ','ซ่อม','ฝนตก','วิภาวดี','แคราย','สะพานพระนั่งเกล้า','รัตนาธิเบศ','พงษ์เพชร','แยกเกษตร','งามวงศ์วาน','บางเขน']\n",
    "#Negatively important words\n",
    "neg_word = ['อุบัติเหตุ','ซ่อม','ฝนตก','จอดเสีย','รถชน','เคลื่อนย้าย','ติดขัด','สะสม','ท้ายแถว']\n",
    "place_word = ['วิภาวดี',\n",
    " 'แคราย',\n",
    " 'สะพานพระนั่งเกล้า',\n",
    " 'รัตนาธิเบศร์',\n",
    " 'พงษ์เพชร',\n",
    " 'เกษตร',\n",
    " 'งามวงศ์วาน',\n",
    " 'บางเขน']\n",
    "place_word_ref = place_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "g6iOmtBCikgk"
   },
   "outputs": [],
   "source": [
    "consumer_key = \"sOnn3bjnHhG6zKKzqbZpW6Ccs\"\n",
    "consumer_secret = \"f5TO0onnROxiE04QbLdyXMBAt2YCc8LIMmtqQTbGQk3yuCYUDk\"\n",
    "access_token = \"1320225693939101696-zko7CVgLHvLMFVpzW4wWsJKnIITtss\"\n",
    "access_token_secret = \"OYAfv4Zz0vEjpAyfIs5PMlkUTB6X4l2TZGb6c87LWGmWM\"\n",
    "#I suggest to regen keys and tokens everytime coding\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "a = api.get_status(912886007451676672, tweet_mode='extended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T18qx7iUikgn"
   },
   "source": [
    "scrape data from #query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bJoHDGfsikgn"
   },
   "outputs": [],
   "source": [
    "#Create random to def\n",
    "def sampling_func(items,k):\n",
    "    #create random samples for printing news (consequence)\n",
    "    sampling_neg = random.sample(items, k)\n",
    "    #create random samples for printing news (place)\n",
    "    sampling_place = random.sample(place_word_ref,k=1)\n",
    "    #concat neg & place\n",
    "    sampling_neg.extend(sampling_place)\n",
    "    sampling_neg.append('#รถติด') #necessary to add a vital keyword\n",
    "    return sampling_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WifnRChbikgq"
   },
   "outputs": [],
   "source": [
    "sampling=sampling_func(neg_word,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cpUoOyWJikgt"
   },
   "outputs": [],
   "source": [
    "#scrape data from twitter query\n",
    "query = sampling_func(neg_word,1)\n",
    "count = 100\n",
    "try:\n",
    "    tweets_q =tweepy.Cursor(api.search, q= query,full_text = True,result_type = 'recent'\n",
    "    ,until_date = date.today()).items(count)\n",
    "    tweets_list_q = [[obj.created_at, obj.id, obj.text] for obj in tweets_q]\n",
    "    tweets_df_q = pd.DataFrame(tweets_list_q,columns=('date_time','id', 'tweet'))\n",
    "    while True:\n",
    "        if len(tweets_df_q.tweet) == 0:\n",
    "            query = sampling_func(neg_word,1)\n",
    "            tweets_q =tweepy.Cursor(api.search, q= query,full_text = True,result_type = 'recent'\n",
    "            ,until_date = date.today()).items(count)\n",
    "            tweets_list_q = [[obj.created_at, obj.id, obj.text] for obj in tweets_q]\n",
    "            tweets_df_q = pd.DataFrame(tweets_list_q,columns=('date_time','id', 'tweet'))\n",
    "        else:\n",
    "            break\n",
    "except BaseException as e:\n",
    "    print('failed on_status,',str(e))\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gpjtji-Bikgw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df_q = tweets_df_q.drop(['date_time','id'],axis=1)\n",
    "#tweets_df_q=tweets_df_q[tweets_df_q['tweet'].str.contains(\"Trump\")] #Change Everytime!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1y9DAZG6ikgy"
   },
   "outputs": [],
   "source": [
    "tweets_df_q.drop_duplicates(keep=\"first\", inplace=True) #Drop duplicated items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE71oGfJikg0"
   },
   "source": [
    "# Pre processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Hz64hGAXikg1"
   },
   "outputs": [],
   "source": [
    "def clean_msg(msg): #Clear all signs\n",
    "    \n",
    "    # delete text in <>\n",
    "    msg = re.sub(r'<.*?>','', msg)\n",
    "    \n",
    "    # delete hashtag\n",
    "    msg = re.sub(r'#','',msg)\n",
    "    \n",
    "    # delete punctuation\n",
    "    for c in string.punctuation:\n",
    "        msg = re.sub(r'\\{}'.format(c),'',msg)\n",
    "    \n",
    "    # delete separator i.e. \\n \\t\n",
    "    msg = ' '.join(msg.split())\n",
    "    \n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pEnVKiolikg3",
    "outputId": "c042231b-603c-47f2-c4db-bc722c610095"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/rodtour/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words') #pull thai word(Bags)\n",
    "th_stop = tuple(thai_stopwords())\n",
    "en_stop = tuple(get_stop_words('en'))\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CQfOze8aikg6"
   },
   "outputs": [],
   "source": [
    "def split_word(text):       \n",
    "    \n",
    "    tokens = word_tokenize(text,engine='newmm')\n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [i for i in tokens if not i in th_stop and not i in en_stop]\n",
    "    \n",
    "    # หารากศัพท์ภาษาไทย และภาษาอังกฤษ\n",
    "    # English\n",
    "    tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "    \n",
    "    # Thai\n",
    "    tokens_temp=[]\n",
    "    for i in tokens:\n",
    "        w_syn = wordnet.synsets(i)\n",
    "        if (len(w_syn)>0) and (len(w_syn[0].lemma_names('tha'))>0):\n",
    "            tokens_temp.append(w_syn[0].lemma_names('tha')[0])\n",
    "        else:\n",
    "            tokens_temp.append(i)\n",
    "    \n",
    "    tokens = tokens_temp\n",
    "    # ลบตัวเลข\n",
    "    tokens = [i for i in tokens if not i.isnumeric()]\n",
    "    # ลบช่องว่าง\n",
    "    tokens = [i for i in tokens if not ' ' in i]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_tB8TaHikg9"
   },
   "source": [
    "# Create Live news Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GsdIXbTvikg9"
   },
   "outputs": [],
   "source": [
    "#Set New dataframe by query\n",
    "df = tweets_df_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Y-Ia5vVgikhH"
   },
   "outputs": [],
   "source": [
    "list_clean_df = [clean_msg(i) for i in df.tweet] #clean msg\n",
    "list_token_df = [split_word(text) for text in list_clean_df] #split words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GhjAFh-CikhJ"
   },
   "outputs": [],
   "source": [
    "#Add token to df\n",
    "df['token'] = list_token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "To7Ddw-hikhL",
    "outputId": "0de20935-6963-475e-89f5-30e7384b20b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['อุบัติเหตุ']\n",
      "1\n",
      "['อุบัติเหตุ']\n"
     ]
    }
   ],
   "source": [
    "label_total = []\n",
    "for i in range(len(df.token)):\n",
    "    label = [txt for txt in df.token.iloc[i] if txt in neg_word]\n",
    "    label = list(set(label))\n",
    "    label_total.append(label)\n",
    "    print(i)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "TOHguKloikhO",
    "outputId": "71de9c38-84b6-46a1-fb8f-daf85dec16df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['รัตนาธิเบศร์']\n",
      "['รัตนาธิเบศร์']\n",
      "['รัตนาธิเบศร์']\n",
      "['รัตนาธิเบศร์']\n"
     ]
    }
   ],
   "source": [
    "place_total = []\n",
    "for i in range(len(df.token)):\n",
    "    place = [txt for txt in df.token.iloc[i] if txt in place_word]\n",
    "    place = list(set(place))\n",
    "    place_total.append(place)\n",
    "    print(place)\n",
    "    print(place)\n",
    "    \n",
    "#Not accurate as the split word is not perfect\n",
    "#Intial solution ==>> Add more place_word\n",
    "\n",
    "place_word.extend(['รัตนา','เพชร','เกล้า','เขน', 'บาง', 'วัฒนะ','แค','ราย', 'งาม', 'วาน'])\n",
    "#concat full word\n",
    "for aa in place_total:\n",
    "    for i in range(len(aa)):\n",
    "        if aa[i] == 'เขน'or aa[i] == 'บาง':\n",
    "             aa[i] = 'บางเขน'\n",
    "        elif aa[i] == 'แค'or aa[i]=='ราย':\n",
    "            aa[i]='แคราย'\n",
    "        elif aa[i]=='เกล้า':\n",
    "            aa[i]='สะพานพระนั่งเกล้า'\n",
    "        elif aa[i]=='รัตนา'or aa[i]=='ธิเบศ':\n",
    "            aa[i]= 'รัตนาธิเบศร์'\n",
    "        elif aa[i]=='พงศ์'or aa[i]=='เพชร':\n",
    "            aa[i]='พงศ์เพชร'\n",
    "        elif aa[i]=='งาม'or aa[i]=='วงศ์'or aa[i]=='วาน':\n",
    "            aa[i]='งามวงศ์วาน'\n",
    "        elif aa[i]==\"แจ้ง\" or aa[i]=='วัฒนะ':\n",
    "            aa[i]='แจ้งวัฒนะ'\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "oGdC6eWAikhQ"
   },
   "outputs": [],
   "source": [
    "df['condition'] = label_total #gern condition to df\n",
    "df['place'] = place_total #gern place to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PBPvPFaBikhS",
    "outputId": "595bbea4-b05b-443e-f1c0-77132124dd2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>token</th>\n",
       "      <th>condition</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @js100radio: 10:10 #อุบัติเหตุ #ถนนรัตนาธิเ...</td>\n",
       "      <td>[RT, js, radio, อุบัติเหตุ, ถ., รัตนาธิเบศร์, ...</td>\n",
       "      <td>[อุบัติเหตุ]</td>\n",
       "      <td>[รัตนาธิเบศร์]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10:10 #อุบัติเหตุ #ถนนรัตนาธิเบศร์ ช่วงถนนเลี่...</td>\n",
       "      <td>[อุบัติเหตุ, ถ., รัตนาธิเบศร์, ถ., เลี่ยง, เมื...</td>\n",
       "      <td>[อุบัติเหตุ]</td>\n",
       "      <td>[รัตนาธิเบศร์]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  RT @js100radio: 10:10 #อุบัติเหตุ #ถนนรัตนาธิเ...   \n",
       "4  10:10 #อุบัติเหตุ #ถนนรัตนาธิเบศร์ ช่วงถนนเลี่...   \n",
       "\n",
       "                                               token     condition  \\\n",
       "0  [RT, js, radio, อุบัติเหตุ, ถ., รัตนาธิเบศร์, ...  [อุบัติเหตุ]   \n",
       "4  [อุบัติเหตุ, ถ., รัตนาธิเบศร์, ถ., เลี่ยง, เมื...  [อุบัติเหตุ]   \n",
       "\n",
       "            place  \n",
       "0  [รัตนาธิเบศร์]  \n",
       "4  [รัตนาธิเบศร์]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import io\n",
    "#from google.colab import files (working vai offline conda prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Dataframe import Data from 'colab_model.csv'\n",
    "df_model = pd.read_csv('COLAB_MODEL.csv')\n",
    "df_model = df_model[['nameDAY','CAL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Arrival Time\n",
    "df.values.tolist()\n",
    "nameDAY = df_model['nameDAY'].tolist()\n",
    "CAL = df_model['CAL'].tolist() \n",
    "\n",
    "# count element\n",
    "countmon = nameDAY.count('จันทร์')\n",
    "counttue = nameDAY.count('อังคาร')\n",
    "countwed = nameDAY.count('พุธ')\n",
    "countthu = nameDAY.count('พฤหัสบดี')\n",
    "countfri = nameDAY.count('ศุกร์')\n",
    "\n",
    "li = df_model.values.tolist() \n",
    "\n",
    "tup = {i:0 for i, v in li}\n",
    "for key, value in li:\n",
    "    tup[key] = tup[key]+value\n",
    "result = list(map(tuple, tup.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y) in result:\n",
    "    if x == 'จันทร์':\n",
    "        mon = y/countmon    #AVG_MONDAY\n",
    "       # print('mon',int(mon))\n",
    "    elif x == 'อังคาร':\n",
    "        tue = y/counttue  #AVG_TUESDAY\n",
    "        #print('tue' , int(tue))\n",
    "    elif x == 'พุธ':\n",
    "        wed = y/countwed  #AVG_WEDNESDAY\n",
    "        #print('wed' ,int(wed))\n",
    "    elif x == 'พฤหัสบดี':\n",
    "        thu = y/countthu  #AVG_THURSDAY\n",
    "        #print('thu' ,int(thu))\n",
    "    elif x == 'ศุกร์':\n",
    "        fri = y/countfri  #AVG_FRIDAY\n",
    "        #print('fri' ,int(fri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workdays dataframe set up & working on apriori algo\n",
    "col_name = ['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก','วิภาวดี','แคราย','สะพานพระนั่งเกล้า','รัตนาธิเบศ','พงษ์เพชร','บางเขน','เกษตร','งามวงศ์วาน']\n",
    "#Monday\n",
    "df_mon = pd.read_csv('COLAB_MODEL_mon.csv')\n",
    "df_mon.drop('nameDAY',inplace=True,axis=1)\n",
    "df_mon.columns = col_name\n",
    "df_mon.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_mon = apriori(df_mon, min_support=0.07, max_len=2, use_colnames=True)\n",
    "\n",
    "#Tuesday\n",
    "df_tue = pd.read_csv('COLAB_MODEL_tue.csv')\n",
    "df_tue.columns = col_name\n",
    "df_tue.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_tue = apriori(df_tue, min_support=0.07,max_len=2, use_colnames=True)\n",
    "\n",
    "#Wednesday\n",
    "df_wed = pd.read_csv('COLAB_MODEL_wed.csv')\n",
    "df_wed.columns = col_name\n",
    "df_wed.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_wed = apriori(df_wed, min_support=0.07,max_len=2 , use_colnames=True)\n",
    "\n",
    "#Thursday\n",
    "df_thu = pd.read_csv('COLAB_MODEL_thu.csv')\n",
    "df_thu.columns = col_name\n",
    "df_thu.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_thu = apriori(df_thu, min_support=0.07,max_len =2, use_colnames=True)\n",
    "\n",
    "#Friday\n",
    "df_fri = pd.read_csv('COLAB_MODEL_fri.csv')\n",
    "df_fri.columns = col_name\n",
    "df_fri.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_fri = apriori(df_fri, min_support=0.07,max_len=2, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Association Rules and filter life stat >5 with >= 0.8 confidence level\n",
    "rules_mon = association_rules(frequent_itemsets_mon, metric=\"lift\", min_threshold=1)\n",
    "rules_mon = rules_mon[(rules_mon['lift']>=5) & rules_mon['confidence']>=0.8] #Monday\n",
    "rules_tue = association_rules(frequent_itemsets_tue, metric=\"lift\", min_threshold=1)\n",
    "rules_tue = rules_tue[(rules_tue['lift']>=3)&rules_tue['confidence']>=0.8] #Tuesday\n",
    "rules_wed = association_rules(frequent_itemsets_wed, metric=\"lift\", min_threshold=1)\n",
    "rules_wed = rules_wed[(rules_wed['lift']>=6)&rules_wed['confidence']>=0.8] #Wednesday\n",
    "rules_thu = association_rules(frequent_itemsets_thu, metric=\"lift\", min_threshold=1)\n",
    "rules_thu = rules_thu[(rules_thu['lift']>=2)&rules_thu['confidence']>=0.5] #Thursday\n",
    "rules_fri = association_rules(frequent_itemsets_fri, metric=\"lift\", min_threshold=1)\n",
    "rules_fri = rules_fri[(rules_fri['lift']>=5)&rules_fri['confidence']>=0.8] #Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>(รัตนาธิเบศ)</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(รัตนาธิเบศ)</td>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     antecedents   consequents  antecedent support  consequent support  \\\n",
       "8        (แคราย)  (งามวงศ์วาน)            0.142857            0.071429   \n",
       "9   (งามวงศ์วาน)       (แคราย)            0.071429            0.142857   \n",
       "16  (งามวงศ์วาน)  (รัตนาธิเบศ)            0.071429            0.142857   \n",
       "17  (รัตนาธิเบศ)  (งามวงศ์วาน)            0.142857            0.071429   \n",
       "\n",
       "     support  confidence  lift  leverage  conviction  \n",
       "8   0.071429         0.5   7.0  0.061224    1.857143  \n",
       "9   0.071429         1.0   7.0  0.061224         inf  \n",
       "16  0.071429         1.0   7.0  0.061224         inf  \n",
       "17  0.071429         0.5   7.0  0.061224    1.857143  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_mon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>(สะพานพระนั่งเกล้า)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(สะพานพระนั่งเกล้า)</td>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(พงษ์เพชร)</td>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>(พงษ์เพชร)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(พงษ์เพชร)</td>\n",
       "      <td>(สะพานพระนั่งเกล้า)</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>0.096939</td>\n",
       "      <td>2.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(สะพานพระนั่งเกล้า)</td>\n",
       "      <td>(พงษ์เพชร)</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>0.096939</td>\n",
       "      <td>2.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>(สะพานพระนั่งเกล้า)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(สะพานพระนั่งเกล้า)</td>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>(พงษ์เพชร)</td>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(งามวงศ์วาน)</td>\n",
       "      <td>(พงษ์เพชร)</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            antecedents          consequents  antecedent support  \\\n",
       "0               (แคราย)  (สะพานพระนั่งเกล้า)            0.285714   \n",
       "1   (สะพานพระนั่งเกล้า)              (แคราย)            0.214286   \n",
       "4            (พงษ์เพชร)              (แคราย)            0.214286   \n",
       "5               (แคราย)           (พงษ์เพชร)            0.285714   \n",
       "8               (แคราย)         (งามวงศ์วาน)            0.285714   \n",
       "9          (งามวงศ์วาน)              (แคราย)            0.285714   \n",
       "12           (พงษ์เพชร)  (สะพานพระนั่งเกล้า)            0.214286   \n",
       "13  (สะพานพระนั่งเกล้า)           (พงษ์เพชร)            0.214286   \n",
       "16         (งามวงศ์วาน)  (สะพานพระนั่งเกล้า)            0.285714   \n",
       "17  (สะพานพระนั่งเกล้า)         (งามวงศ์วาน)            0.214286   \n",
       "26           (พงษ์เพชร)         (งามวงศ์วาน)            0.214286   \n",
       "27         (งามวงศ์วาน)           (พงษ์เพชร)            0.285714   \n",
       "\n",
       "    consequent support   support  confidence      lift  leverage  conviction  \n",
       "0             0.214286  0.214286    0.750000  3.500000  0.153061    3.142857  \n",
       "1             0.285714  0.214286    1.000000  3.500000  0.153061         inf  \n",
       "4             0.285714  0.214286    1.000000  3.500000  0.153061         inf  \n",
       "5             0.214286  0.214286    0.750000  3.500000  0.153061    3.142857  \n",
       "8             0.285714  0.285714    1.000000  3.500000  0.204082         inf  \n",
       "9             0.285714  0.285714    1.000000  3.500000  0.204082         inf  \n",
       "12            0.214286  0.142857    0.666667  3.111111  0.096939    2.357143  \n",
       "13            0.214286  0.142857    0.666667  3.111111  0.096939    2.357143  \n",
       "16            0.214286  0.214286    0.750000  3.500000  0.153061    3.142857  \n",
       "17            0.285714  0.214286    1.000000  3.500000  0.153061         inf  \n",
       "26            0.285714  0.214286    1.000000  3.500000  0.153061         inf  \n",
       "27            0.214286  0.214286    0.750000  3.500000  0.153061    3.142857  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_tue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(รัตนาธิเบศ)</td>\n",
       "      <td>(สะพานพระนั่งเกล้า)</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.115556</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(สะพานพระนั่งเกล้า)</td>\n",
       "      <td>(รัตนาธิเบศ)</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.115556</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           antecedents          consequents  antecedent support  \\\n",
       "4         (รัตนาธิเบศ)  (สะพานพระนั่งเกล้า)            0.133333   \n",
       "5  (สะพานพระนั่งเกล้า)         (รัตนาธิเบศ)            0.133333   \n",
       "\n",
       "   consequent support   support  confidence  lift  leverage  conviction  \n",
       "4            0.133333  0.133333         1.0   7.5  0.115556         inf  \n",
       "5            0.133333  0.133333         1.0   7.5  0.115556         inf  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_wed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>(รัตนาธิเบศ)</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(รัตนาธิเบศ)</td>\n",
       "      <td>(แคราย)</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     antecedents   consequents  antecedent support  consequent support  \\\n",
       "12       (แคราย)  (รัตนาธิเบศ)            0.071429            0.142857   \n",
       "13  (รัตนาธิเบศ)       (แคราย)            0.142857            0.071429   \n",
       "\n",
       "     support  confidence  lift  leverage  conviction  \n",
       "12  0.071429         1.0   7.0  0.061224         inf  \n",
       "13  0.071429         0.5   7.0  0.061224    1.857143  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_fri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>token</th>\n",
       "      <th>condition</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @js100radio: 10:10 #อุบัติเหตุ #ถนนรัตนาธิเ...</td>\n",
       "      <td>[RT, js, radio, อุบัติเหตุ, ถ., รัตนาธิเบศร์, ...</td>\n",
       "      <td>[อุบัติเหตุ]</td>\n",
       "      <td>[รัตนาธิเบศร์]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10:10 #อุบัติเหตุ #ถนนรัตนาธิเบศร์ ช่วงถนนเลี่...</td>\n",
       "      <td>[อุบัติเหตุ, ถ., รัตนาธิเบศร์, ถ., เลี่ยง, เมื...</td>\n",
       "      <td>[อุบัติเหตุ]</td>\n",
       "      <td>[รัตนาธิเบศร์]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  \\\n",
       "0  RT @js100radio: 10:10 #อุบัติเหตุ #ถนนรัตนาธิเ...   \n",
       "4  10:10 #อุบัติเหตุ #ถนนรัตนาธิเบศร์ ช่วงถนนเลี่...   \n",
       "\n",
       "                                               token     condition  \\\n",
       "0  [RT, js, radio, อุบัติเหตุ, ถ., รัตนาธิเบศร์, ...  [อุบัติเหตุ]   \n",
       "4  [อุบัติเหตุ, ถ., รัตนาธิเบศร์, ถ., เลี่ยง, เมื...  [อุบัติเหตุ]   \n",
       "\n",
       "            place  \n",
       "0  [รัตนาธิเบศร์]  \n",
       "4  [รัตนาธิเบศร์]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6CoBKPSikhV"
   },
   "source": [
    "# Notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "IX4e6swuikhV"
   },
   "outputs": [],
   "source": [
    "def Lineconfig(command):\n",
    "\turl = 'https://notify-api.line.me/api/notify'\n",
    "\ttoken = '8c4Do0dvhOAa5YRx0skmzphfO1KpF1coWDHFYgeI6Z6' ## EDIT\n",
    "\theader = {'content-type':'application/x-www-form-urlencoded','Authorization':'Bearer '+token}\n",
    "\treturn requests.post(url, headers=header, data = command)\n",
    "\n",
    "def sendtext(message):\n",
    "\t# send plain text to line\n",
    "\tcommand = {'message':message}\n",
    "\treturn Lineconfig(command)\n",
    "\n",
    "def sendcon(condition):\n",
    "\t# send condition\n",
    "\tcommand = {'message':condition}\n",
    "\treturn Lineconfig(command)\n",
    "\n",
    "def sendplace(place):\n",
    "\t# send place\n",
    "\tcommand = {'message':place}\n",
    "\treturn Lineconfig(command)\n",
    "\n",
    "def sticker(sticker_id,package_id,message=' '):\n",
    "\tcommand = {'message':message,'stickerPackageId':package_id,'stickerId':sticker_id}\n",
    "\treturn Lineconfig(command)\n",
    "\n",
    "def sendnews(news):\n",
    "\t# send news\n",
    "\tcommand = {'message':news}\n",
    "\treturn Lineconfig(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "T0v2xY-VikhY"
   },
   "outputs": [],
   "source": [
    "#define time(arrival time) and notify function with each day\n",
    "day = date.today().weekday()\n",
    "if day == 0:\n",
    "    time = int(mon)\n",
    "    #aviod_place = [set(i)for i in rules_mon.consequents] #from a model suggestion\n",
    "elif day == 1:\n",
    "    time = int(tue)\n",
    "    #aviod_place = [set(i)for i in rules_tue.consequents]\n",
    "elif day == 2:\n",
    "    time = int(wed)\n",
    "    #aviod_place = [set(i)for i in rules_wed.consequents]\n",
    "elif day == 3:\n",
    "    time = int(thu)\n",
    "    #aviod_place = [set(i)for i in rules_thu.consequents]\n",
    "elif day == 4:\n",
    "    time = int(fri)\n",
    "    #aviod_place = [set(i)for i in rules_fri.consequents]\n",
    "else:\n",
    "    time=\"Weekend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Construct list of condition, place, avoid_place(no duplicate)\n",
    "condition_ls = [] #df.condition\n",
    "place_ls = [] #df.place\n",
    "for num in range(0,len(df.condition)):\n",
    "    for txt in df.condition.iloc[num]:\n",
    "        condition_ls.append(txt)\n",
    "condition_ls = set(condition_ls)\n",
    "for num in range(0,len(df.place)):\n",
    "    for txt in df.place.iloc[num]:\n",
    "        place_ls.append(txt)\n",
    "place_ls = set(place_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten list\n",
    "def flatten(l):\n",
    "    flatList = []\n",
    "    for elem in l:\n",
    "        if type(elem) == list:\n",
    "            for e in elem:\n",
    "                flatList.append(e)\n",
    "        else:\n",
    "            flatList.append(elem)\n",
    "    return flatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map df.place with rules_day(dataframe)\n",
    "def map_place(antecedent): #where you want to map\n",
    "    map_list =[]\n",
    "    con_list = []\n",
    "    try:\n",
    "        for text in antecedent: con_list.append(list(text))\n",
    "        con_list = flatten(con_list)\n",
    "        for txt in con_list:\n",
    "            if txt in place_ls: #compare to place in scraped news; If it is found,keep. Unless, not keep!!\n",
    "                map_list.append(txt)\n",
    "                return map_list\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,',str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frozen(obj):\n",
    "    try:\n",
    "        frozenset(obj)\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,',str(e))\n",
    "        print('No suggestion for today!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "goj05VREikha"
   },
   "outputs": [],
   "source": [
    "#Execute program\n",
    "def execute_notice(time,condition,place):\n",
    "    sticker(3,6,\"Good Morning\")\n",
    "    sendtext(\"การเดินทางวันนี้ใช้เวลาประมาณ {} นาที\".format(time))\n",
    "    sendcon(\"การจราจรโดยรวมมีปัญหา {}\".format(condition))\n",
    "    sendplace(\"เส้นทางที่มีปัญหา {}\".format(place))\n",
    "\n",
    "def execute_news(news):\n",
    "    sendnews(\"สำหรับข่าวเพิ่มเติม {}\".format(news))\n",
    "\n",
    "def asso_rule(days):\n",
    "    if days ==0:\n",
    "        try:\n",
    "            #show consequences\n",
    "            test=rules_thu[rules_mon['antecedents'] == frozenset(map_place(rules_mon.antecedents))]\n",
    "            test2 = test[['antecedents','consequents','confidence','lift']]\n",
    "            sendtext(\"Possible traffic congession are {}\".format(test2.consequents))\n",
    "            sendtext(\"See possible place statistical numbers {}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    elif days ==1:\n",
    "        try:\n",
    "            #show consequences\n",
    "            test=rules_thu[rules_tue['antecedents'] == frozenset(map_place(rules_tue.antecedents))]\n",
    "            test2 = test[['antecedents','consequents','confidence','lift']]\n",
    "            sendtext(\"Possible traffic congession are {}\".format(test2.consequents))\n",
    "            sendtext(\"See statistical numbers {}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    elif days ==2:\n",
    "        try:\n",
    "            #show consequences\n",
    "            test=rules_thu[rules_wed['antecedents'] == frozenset(map_place(rules_wed.antecedents))]\n",
    "            test2 = test[['antecedents','consequents','confidence','lift']]\n",
    "            sendtext(\"Possible traffic congession are {}\".format(test2.consequents))\n",
    "            sendtext(\"See statistical numbers {}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    elif days ==3:\n",
    "        try:\n",
    "            #show consequences\n",
    "            test=rules_thu[rules_thu['antecedents'] == frozenset(map_place(rules_thu.antecedents))]\n",
    "            test2 = test[['antecedents','consequents','confidence','lift']]\n",
    "            sendtext(\"Possible traffic congession are {}\".format(test2.consequents))\n",
    "            sendtext(\"See statistical numbers {}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    elif days ==4:\n",
    "        try:\n",
    "            #show consequences\n",
    "            test=rules_thu[rules_fri['antecedents'] == frozenset(map_place(rules_fri.antecedents))]\n",
    "            test2 = test[['antecedents','consequents','confidence','lift']]\n",
    "            sendtext(\"Possible traffic congession are {}\".format(test2.consequents))\n",
    "            sendtext(\"See statistical numbers {}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    else:\n",
    "        sendtext(\"Weekend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Dv-Q3AN6ikhc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on_status, 'NoneType' object is not iterable\n",
      "No Relevant data Today!!\n"
     ]
    }
   ],
   "source": [
    "execute_notice(time,condition_ls,place_ls)\n",
    "\n",
    "for i in range(0,2): # 2 latest news\n",
    "    execute_news(news=df.tweet.iloc[i])\n",
    "    \n",
    "asso_rule(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed on_status, 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "asso_rule(day)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Monday = 0, Sunday =6"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def asso_rule(days):\n",
    "    if days ==1:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_mon['antecedents'] == frozenset(map_place(rules_mon.antecedents))]\n",
    "        #grap all consequents\n",
    "        con_place = []\n",
    "        for pla in test.consequents:\n",
    "            con_place.append(list(pla))\n",
    "            con_place= set(flatten(con_place))\n",
    "        sendtext(\"Possible jammed places {}\".format(con_place))\n",
    "        test2 = test[['consequents','confidence','lift']]\n",
    "        sendtext(\"See statistical numbers {}\".format(test2))\n",
    "    elif days ==2:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_tue['antecedents'] == frozenset(map_place(rules_tue.antecedents))]\n",
    "        #grap all consequents\n",
    "        con_place = []\n",
    "        for pla in test.consequents:\n",
    "            con_place.append(list(pla))\n",
    "            con_place= set(flatten(con_place))\n",
    "        sendtext(\"Possible jammed places {}\".format(con_place))\n",
    "        test2 = test[['consequents','confidence','lift']]\n",
    "        sendtext(\"See statistical numbers {}\".format(test2))\n",
    "    elif days ==3:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_wed['antecedents'] == frozenset(map_place(rules_wed.antecedents))]\n",
    "        #grap all consequents\n",
    "        con_place = []\n",
    "        for pla in test.consequents:\n",
    "            con_place.append(list(pla))\n",
    "            con_place= set(flatten(con_place))\n",
    "        sendtext(\"Possible jammed places {}\".format(con_place))\n",
    "        test2 = test[['consequents','confidence','lift']]\n",
    "        sendtext(\"See statistical numbers {}\".format(test2))\n",
    "    elif days ==4:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_thu['antecedents'] == frozenset(map_place(rules_thu.antecedents))]\n",
    "        #grap all consequents\n",
    "        #result_place = list()\n",
    "        #for pla in test.consequents:\n",
    "         #   result_place.append(pla)\n",
    "          #  result_place= set(flatten(result_place))\n",
    "        #sendtext(\"Possible jammed places {}\".format(result_place))\n",
    "        #test2 = test[['consequents','confidence','lift']]\n",
    "        sendtext(\"See statistical numbers {}\".format(test))\n",
    "    elif days ==5:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_fri['antecedents'] == frozenset(map_place(rules_fri.antecedents))]\n",
    "        #grap all consequents\n",
    "        con_place = []\n",
    "        for pla in test.consequents:\n",
    "            con_place.append(list(pla))\n",
    "            con_place= set(flatten(con_place))\n",
    "        sendtext(\"Possible jammed places {}\".format(con_place))\n",
    "        sendtext(\"See statistical numbers {}\".format(test2))\n",
    "    else:\n",
    "        sendtext(\"Weekend\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Not able to use\n",
    "aviod_place = [set(i)for i in rules_fri.consequents]\n",
    "aviod_place"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Full Al.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
