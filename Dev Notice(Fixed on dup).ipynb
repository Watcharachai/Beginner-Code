{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Watcharachai/Beginner-Code/blob/master/Full_Al_Line_Notice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DybxhttnikgZ"
   },
   "source": [
    "# Import Packages and Produce Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AQEnvFVAikga"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import schedule\n",
    "import pip\n",
    "\n",
    "import pythainlp\n",
    "from pythainlp import word_tokenize\n",
    "#from pythainlp.corpus import stopwords\n",
    "from pythainlp.corpus import wordnet\n",
    "from stop_words import get_stop_words\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import words\n",
    "\n",
    "import tweepy\n",
    "import random\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XrK5Q0isikge"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wflC23JIikgh"
   },
   "source": [
    "# Pull Current Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g6iOmtBCikgk"
   },
   "outputs": [],
   "source": [
    "consumer_key = \"tMnrLlvoOo8jbPO96gw5aSe05\"\n",
    "consumer_secret = \"muM7EAWBOjtHtSwPyeZFHLhDR74zJEg3bV2Q55rF3UDhtjK2yW\"\n",
    "access_token = \"2477045196-id4wi8Q7hVfXp15xypGeAYumOtUPVgtMneRwO46\"\n",
    "access_token_secret = \"PEXXJRQrHjfCki5cs3r8P97dH8UXBcxHTtoaD60xYN908\"\n",
    "#AAAAAAAAAAAAAAAAAAAAALCcJAEAAAAAfQOSEK8apb%2BOKlJxFKiseIh%2Bjds%3DICWj1bf9ya3s89nnH63h9Equw9U881xvJM4w1cxFNyHMZ3c0Ig (bear Token)\n",
    "#I suggest to regen keys and tokens everytime coding\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T18qx7iUikgn"
   },
   "source": [
    "scrape data from #query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "bJoHDGfsikgn"
   },
   "outputs": [],
   "source": [
    "#Create random to def (without replacement function) 17*17 times (289) per\n",
    "def sampling_func(items,k):\n",
    "    #create random samples for printing news (consequence)\n",
    "    sampling_neg = random.sample(items, k)\n",
    "    #create random samples for printing news (place)\n",
    "    sampling_place = random.sample(place_word_ref,k=1)\n",
    "    #concat neg & place\n",
    "    sampling_neg.extend(sampling_place)\n",
    "    sampling_neg.append('รถติด') #necessary to add a vital keyword\n",
    "    return sampling_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "2-b9-vLFikgi"
   },
   "outputs": [],
   "source": [
    "#Define important words\n",
    "bag_words = ['อุบัติเหตุ','ซ่อม','ฝนตก','วิภาวดี','แคราย','สะพานพระนั่งเกล้า','รัตนาธิเบศร์','พงษ์เพชร','แยกเกษตร','งามวงศ์วาน','บางเขน']\n",
    "#Negatively important words\n",
    "neg_word = ['อุบัติเหตุ','ซ่อม','ฝนตก','จอดเสีย','รถชน','เคลื่อนย้าย','ติดขัด','สะสม','ท้ายแถว']\n",
    "place_word = ['วิภาวดี','แคราย','สะพานพระนั่งเกล้า','รัตนาธิเบศร์','พงษ์เพชร','เกษตร','งามวงศ์วาน','บางเขน']\n",
    "place_word_ref = place_word\n",
    "#setup current time\n",
    "until_date = datetime.now().strftime('%Y-%m-%d,%H:%M:%S')\n",
    "full_dates = datetime.now().strftime('%A %d-%B-%Y')\n",
    "#setup yesterday\n",
    "yesterday = (datetime.now() - timedelta(days = 1)).strftime('%Y-%m-%d,%H:%M:%S') #can change a lag to hours, days, weeks, min or anys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['สะสม', 'งามวงศ์วาน', '#รถติด']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "cpUoOyWJikgt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ติดขัด', 'บางเขน', 'รถติด']\n",
      "(0, 3)\n",
      "['ซ่อม', 'แคราย', 'รถติด']\n",
      "(0, 3)\n",
      "['ติดขัด', 'แคราย', 'รถติด']\n",
      "(0, 3)\n",
      "['รถชน', 'งามวงศ์วาน', 'รถติด']\n",
      "(0, 3)\n",
      "['ติดขัด', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['ฝนตก', 'รัตนาธิเบศร์', 'รถติด']\n",
      "(0, 3)\n",
      "['ซ่อม', 'รัตนาธิเบศร์', 'รถติด']\n",
      "(0, 3)\n",
      "['ท้ายแถว', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['สะสม', 'สะพานพระนั่งเกล้า', 'รถติด']\n",
      "(0, 3)\n",
      "['สะสม', 'แคราย', 'รถติด']\n",
      "(0, 3)\n",
      "['สะสม', 'งามวงศ์วาน', 'รถติด']\n",
      "(0, 3)\n",
      "['ซ่อม', 'งามวงศ์วาน', 'รถติด']\n",
      "(0, 3)\n",
      "['รถชน', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['ติดขัด', 'วิภาวดี', 'รถติด']\n",
      "(0, 3)\n",
      "['เคลื่อนย้าย', 'สะพานพระนั่งเกล้า', 'รถติด']\n",
      "(0, 3)\n",
      "['จอดเสีย', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['อุบัติเหตุ', 'รัตนาธิเบศร์', 'รถติด']\n",
      "(0, 3)\n",
      "['อุบัติเหตุ', 'รัตนาธิเบศร์', 'รถติด']\n",
      "(0, 3)\n",
      "['ติดขัด', 'งามวงศ์วาน', 'รถติด']\n",
      "(0, 3)\n",
      "['รถชน', 'วิภาวดี', 'รถติด']\n",
      "(0, 3)\n",
      "['เคลื่อนย้าย', 'วิภาวดี', 'รถติด']\n",
      "(0, 3)\n",
      "['อุบัติเหตุ', 'แคราย', 'รถติด']\n",
      "(0, 3)\n",
      "['ท้ายแถว', 'รัตนาธิเบศร์', 'รถติด']\n",
      "(0, 3)\n",
      "['สะสม', 'สะพานพระนั่งเกล้า', 'รถติด']\n",
      "(0, 3)\n",
      "['เคลื่อนย้าย', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['ท้ายแถว', 'บางเขน', 'รถติด']\n",
      "(0, 3)\n",
      "['จอดเสีย', 'บางเขน', 'รถติด']\n",
      "(0, 3)\n",
      "['ซ่อม', 'วิภาวดี', 'รถติด']\n",
      "(0, 3)\n",
      "['รถชน', 'วิภาวดี', 'รถติด']\n",
      "(0, 3)\n",
      "['เคลื่อนย้าย', 'วิภาวดี', 'รถติด']\n",
      "(0, 3)\n",
      "['จอดเสีย', 'วิภาวดี', 'รถติด']\n",
      "(0, 3)\n",
      "['ซ่อม', 'วิภาวดี', 'รถติด']\n",
      "(0, 3)\n",
      "['ท้ายแถว', 'งามวงศ์วาน', 'รถติด']\n",
      "(0, 3)\n",
      "['สะสม', 'สะพานพระนั่งเกล้า', 'รถติด']\n",
      "(0, 3)\n",
      "['ฝนตก', 'รัตนาธิเบศร์', 'รถติด']\n",
      "(0, 3)\n",
      "['ติดขัด', 'งามวงศ์วาน', 'รถติด']\n",
      "(0, 3)\n",
      "['ฝนตก', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['ติดขัด', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['เคลื่อนย้าย', 'วิภาวดี', 'รถติด']\n",
      "(0, 3)\n",
      "['ซ่อม', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['รถชน', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['เคลื่อนย้าย', 'บางเขน', 'รถติด']\n",
      "(0, 3)\n",
      "['ฝนตก', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['ท้ายแถว', 'แคราย', 'รถติด']\n",
      "(0, 3)\n",
      "['ซ่อม', 'สะพานพระนั่งเกล้า', 'รถติด']\n",
      "(0, 3)\n",
      "['อุบัติเหตุ', 'งามวงศ์วาน', 'รถติด']\n",
      "(0, 3)\n",
      "['รถชน', 'เกษตร', 'รถติด']\n",
      "(0, 3)\n",
      "['ซ่อม', 'วิภาวดี', 'รถติด']\n",
      "failed on_status, \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'sleep'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWantReadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0mcnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1933\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_do_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36m_raise_ssl_error\u001b[0;34m(self, ssl, result)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWantReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_ERROR_WANT_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWantReadError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-90981ede6e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mtweets_q\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muntil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muntil_date\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myesterday\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mtweets_list_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets_q\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mtweets_df_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_list_q\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date_time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tweet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-90981ede6e95>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mtweets_q\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muntil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muntil_date\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myesterday\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'recent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mtweets_list_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets_q\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mtweets_df_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_list_q\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'date_time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tweet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    188\u001b[0m                                                 \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                                                 proxies=self.api.proxy)\n\u001b[0m\u001b[1;32m    190\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mssl_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWantReadError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"select timed out\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mwait_for_read\u001b[0;34m(sock, timeout)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \"\"\"\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwait_for_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mpoll_wait_for_socket\u001b[0;34m(sock, read, write, timeout)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_retry_on_intr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_poll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36m_retry_on_intr\u001b[0;34m(fn, timeout)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_retry_on_intr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/wait.py\u001b[0m in \u001b[0;36mdo_poll\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpoll_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-90981ede6e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'failed on_status,'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'sleep'"
     ]
    }
   ],
   "source": [
    "#scrape data from twitter query\n",
    "query = sampling_func(neg_word,1)\n",
    "count = 20\n",
    "print(query)\n",
    "try:\n",
    "    tweets_q =tweepy.Cursor(api.search, q= query,until = until_date ,since=yesterday,full_text = True,result_type = 'recent').items(count) #full text is only 140 characters\n",
    "    tweets_list_q = [[obj.created_at, obj.id, obj.text] for obj in tweets_q]\n",
    "    tweets_df_q = pd.DataFrame(tweets_list_q,columns=('date_time','id', 'tweet'))\n",
    "    print(tweets_df_q.shape)\n",
    "    if len(tweets_df_q.tweet) == 0:\n",
    "        while True:\n",
    "            if len(tweets_df_q.tweet) == 0:\n",
    "                query = sampling_func(neg_word,1)\n",
    "                print(query)\n",
    "                tweets_q =tweepy.Cursor(api.search, q= query,until = until_date ,since=yesterday,full_text = True,result_type = 'recent').items(count)\n",
    "                tweets_list_q = [[obj.created_at, obj.id, obj.text] for obj in tweets_q]\n",
    "                tweets_df_q = pd.DataFrame(tweets_list_q,columns=('date_time','id', 'tweet'))\n",
    "                print(tweets_df_q.shape)\n",
    "            else:\n",
    "                break\n",
    "    else:\n",
    "        tweets_df_q\n",
    "except BaseException as e:\n",
    "    print('failed on_status,',str(e))\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "gpjtji-Bikgw",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_df_q = tweets_df_q.drop(['date_time','id'],axis=1)\n",
    "#tweets_df_q=tweets_df_q[tweets_df_q['tweet'].str.contains(\"Trump\")] #Change Everytime!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "1y9DAZG6ikgy"
   },
   "outputs": [],
   "source": [
    "tweets_df_q.drop_duplicates(keep=\"first\", inplace=True) #Drop duplicated items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LE71oGfJikg0"
   },
   "source": [
    "# Pre processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "Hz64hGAXikg1"
   },
   "outputs": [],
   "source": [
    "def clean_msg(msg): #Clear all signs\n",
    "    \n",
    "    # delete text in <>\n",
    "    msg = re.sub(r'<.*?>','', msg)\n",
    "    \n",
    "    # delete hashtag\n",
    "    msg = re.sub(r'#','',msg)\n",
    "    \n",
    "    # delete punctuation\n",
    "    for c in string.punctuation:\n",
    "        msg = re.sub(r'\\{}'.format(c),'',msg)\n",
    "    \n",
    "    # delete separator i.e. \\n \\t\n",
    "    msg = ' '.join(msg.split())\n",
    "    \n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "pEnVKiolikg3",
    "outputId": "c042231b-603c-47f2-c4db-bc722c610095"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/rodtour/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words') #pull thai word(Bags)\n",
    "th_stop = tuple(thai_stopwords())\n",
    "en_stop = tuple(get_stop_words('en'))\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "CQfOze8aikg6"
   },
   "outputs": [],
   "source": [
    "def split_word(text):       \n",
    "    \n",
    "    tokens = word_tokenize(text,engine='newmm')\n",
    "    \n",
    "    # Remove stop words\n",
    "    tokens = [i for i in tokens if not i in th_stop and not i in en_stop]\n",
    "    \n",
    "    # หารากศัพท์ภาษาไทย และภาษาอังกฤษ\n",
    "    # English\n",
    "    tokens = [p_stemmer.stem(i) for i in tokens]\n",
    "    \n",
    "    # Thai\n",
    "    tokens_temp=[]\n",
    "    for i in tokens:\n",
    "        w_syn = wordnet.synsets(i)\n",
    "        if (len(w_syn)>0) and (len(w_syn[0].lemma_names('tha'))>0):\n",
    "            tokens_temp.append(w_syn[0].lemma_names('tha')[0])\n",
    "        else:\n",
    "            tokens_temp.append(i)\n",
    "    \n",
    "    tokens = tokens_temp\n",
    "    # ลบตัวเลข\n",
    "    tokens = [i for i in tokens if not i.isnumeric()]\n",
    "    # ลบช่องว่าง\n",
    "    tokens = [i for i in tokens if not ' ' in i]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_tB8TaHikg9"
   },
   "source": [
    "# Create Live news Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "GsdIXbTvikg9"
   },
   "outputs": [],
   "source": [
    "#Set New dataframe by query\n",
    "df = tweets_df_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "Y-Ia5vVgikhH"
   },
   "outputs": [],
   "source": [
    "list_clean_df = [clean_msg(i) for i in df.tweet] #clean msg\n",
    "list_token_df = [split_word(text) for text in list_clean_df] #split words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "GhjAFh-CikhJ"
   },
   "outputs": [],
   "source": [
    "#Add token to df\n",
    "df['token'] = list_token_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "To7Ddw-hikhL",
    "outputId": "0de20935-6963-475e-89f5-30e7384b20b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['อุบัติเหตุ']\n",
      "['อุบัติเหตุ']\n"
     ]
    }
   ],
   "source": [
    "label_total = []\n",
    "for i in range(len(df.token)):\n",
    "    label = [txt for txt in df.token.iloc[i] if txt in neg_word]\n",
    "    label = list(set(label))\n",
    "    label_total.append(label)\n",
    "    print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "TOHguKloikhO",
    "outputId": "71de9c38-84b6-46a1-fb8f-daf85dec16df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['งาม', 'เพชร', 'เขน']\n",
      "['งาม', 'เพชร', 'เขน']\n"
     ]
    }
   ],
   "source": [
    "place_total = []\n",
    "for i in range(len(df.token)):\n",
    "    place = [txt for txt in df.token.iloc[i] if txt in place_word]\n",
    "    place = list(set(place))\n",
    "    place_total.append(place)\n",
    "    print(place)\n",
    "    \n",
    "#Not accurate as the split word is not perfect\n",
    "#Intial solution ==>> Add more place_word\n",
    "\n",
    "place_word.extend(['รัตนา','เพชร','เกล้า','เขน', 'บาง', 'วัฒนะ','แค','ราย', 'งาม', 'วาน'])\n",
    "#concat full word\n",
    "for aa in place_total:\n",
    "    for i in range(len(aa)):\n",
    "        if aa[i] == 'เขน'or aa[i] == 'บาง':\n",
    "             aa[i] = 'บางเขน'\n",
    "        elif aa[i] == 'แค'or aa[i]=='ราย':\n",
    "            aa[i]='แคราย'\n",
    "        elif aa[i]=='เกล้า':\n",
    "            aa[i]='สะพานพระนั่งเกล้า'\n",
    "        elif aa[i]=='รัตนา'or aa[i]=='ธิเบศ':\n",
    "            aa[i]= 'รัตนาธิเบศร์'\n",
    "        elif aa[i]=='พงศ์'or aa[i]=='เพชร':\n",
    "            aa[i]='พงศ์เพชร'\n",
    "        elif aa[i]=='งาม'or aa[i]=='วงศ์'or aa[i]=='วาน':\n",
    "            aa[i]='งามวงศ์วาน'\n",
    "        elif aa[i]==\"แจ้ง\" or aa[i]=='วัฒนะ':\n",
    "            aa[i]='แจ้งวัฒนะ'\n",
    "        elif aa[i] == 'วิภา' or aa[i]=='วิภาวดี':\n",
    "            aa[i] = 'วิภาวดี'\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_word.extend(['รัตนา','เพชร','เกล้า','เขน', 'บาง', 'วัฒนะ','แค','ราย', 'งาม', 'วาน'])\n",
    "#concat full word\n",
    "for aa in place_total:\n",
    "    for i in range(len(aa)):\n",
    "        if aa[i] == 'เขน'or aa[i] == 'บาง':\n",
    "             aa[i] = 'บางเขน'\n",
    "        elif aa[i] == 'แค'or aa[i]=='ราย':\n",
    "            aa[i]='แคราย'\n",
    "        elif aa[i]=='เกล้า':\n",
    "            aa[i]='สะพานพระนั่งเกล้า'\n",
    "        elif aa[i]=='รัตนา'or aa[i]=='ธิเบศ':\n",
    "            aa[i]= 'รัตนาธิเบศร์'\n",
    "        elif aa[i]=='พงศ์'or aa[i]=='เพชร':\n",
    "            aa[i]='พงศ์เพชร'\n",
    "        elif aa[i]=='งาม'or aa[i]=='วงศ์'or aa[i]=='วาน':\n",
    "            aa[i]='งามวงศ์วาน'\n",
    "        elif aa[i]==\"แจ้ง\" or aa[i]=='วัฒนะ':\n",
    "            aa[i]='แจ้งวัฒนะ'\n",
    "        elif aa[i] == 'วิภา' or aa[i]=='วิภาวดี':\n",
    "            aa[i] = 'วิภาวดี'\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "oGdC6eWAikhQ"
   },
   "outputs": [],
   "source": [
    "df['condition'] = label_total #gern condition to df\n",
    "df['place'] = place_total #gern place to df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import io\n",
    "#from google.colab import files (working vai offline conda prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct Dataframe import Data from 'colab_model.csv'\n",
    "df_model = pd.read_csv('COLAB_MODEL.csv')\n",
    "df_model = df_model[['nameDAY','CAL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Arrival Time\n",
    "df.values.tolist()\n",
    "nameDAY = df_model['nameDAY'].tolist()\n",
    "CAL = df_model['CAL'].tolist() \n",
    "\n",
    "# count element\n",
    "countmon = nameDAY.count('จันทร์')\n",
    "counttue = nameDAY.count('อังคาร')\n",
    "countwed = nameDAY.count('พุธ')\n",
    "countthu = nameDAY.count('พฤหัสบดี')\n",
    "countfri = nameDAY.count('ศุกร์')\n",
    "\n",
    "li = df_model.values.tolist() \n",
    "\n",
    "tup = {i:0 for i, v in li}\n",
    "for key, value in li:\n",
    "    tup[key] = tup[key]+value\n",
    "result = list(map(tuple, tup.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (x,y) in result:\n",
    "    if x == 'จันทร์':\n",
    "        mon = y/countmon    #AVG_MONDAY\n",
    "       # print('mon',int(mon))\n",
    "    elif x == 'อังคาร':\n",
    "        tue = y/counttue  #AVG_TUESDAY\n",
    "        #print('tue' , int(tue))\n",
    "    elif x == 'พุธ':\n",
    "        wed = y/countwed  #AVG_WEDNESDAY\n",
    "        #print('wed' ,int(wed))\n",
    "    elif x == 'พฤหัสบดี':\n",
    "        thu = y/countthu  #AVG_THURSDAY\n",
    "        #print('thu' ,int(thu))\n",
    "    elif x == 'ศุกร์':\n",
    "        fri = y/countfri  #AVG_FRIDAY\n",
    "        #print('fri' ,int(fri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workdays dataframe set up & working on apriori algo\n",
    "col_name = ['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก','วิภาวดี','แคราย','สะพานพระนั่งเกล้า','รัตนาธิเบศร์','พงษ์เพชร','บางเขน','เกษตร','งามวงศ์วาน']\n",
    "#Monday\n",
    "df_mon = pd.read_csv('COLAB_MODEL_mon.csv')\n",
    "df_mon.drop('nameDAY',inplace=True,axis=1)\n",
    "df_mon.columns = col_name\n",
    "df_mon.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_mon = apriori(df_mon, min_support=0.07, max_len=2, use_colnames=True)\n",
    "\n",
    "#Tuesday\n",
    "df_tue = pd.read_csv('COLAB_MODEL_tue.csv')\n",
    "df_tue.columns = col_name\n",
    "df_tue.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_tue = apriori(df_tue, min_support=0.07,max_len=2, use_colnames=True)\n",
    "\n",
    "#Wednesday\n",
    "df_wed = pd.read_csv('COLAB_MODEL_wed.csv')\n",
    "df_wed.columns = col_name\n",
    "df_wed.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_wed = apriori(df_wed, min_support=0.07,max_len=2 , use_colnames=True)\n",
    "\n",
    "#Thursday\n",
    "df_thu = pd.read_csv('COLAB_MODEL_thu.csv')\n",
    "df_thu.columns = col_name\n",
    "df_thu.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_thu = apriori(df_thu, min_support=0.07,max_len =2, use_colnames=True)\n",
    "\n",
    "#Friday\n",
    "df_fri = pd.read_csv('COLAB_MODEL_fri.csv')\n",
    "df_fri.columns = col_name\n",
    "df_fri.drop(['รถติด','อุบัติเหตุ','ซ่อม','ฝนตก'],inplace=True,axis=1)\n",
    "frequent_itemsets_fri = apriori(df_fri, min_support=0.07,max_len=2, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Association Rules and filter life stat >5 with >= 0.8 confidence level\n",
    "rules_mon = association_rules(frequent_itemsets_mon, metric=\"lift\", min_threshold=1)\n",
    "#rules_mon = rules_mon[(rules_mon['lift']>=5) & rules_mon['confidence']>=0.8] #Monday\n",
    "rules_tue = association_rules(frequent_itemsets_tue, metric=\"lift\", min_threshold=1)\n",
    "#rules_tue = rules_tue[(rules_tue['lift']>=3)&rules_tue['confidence']>=0.8] #Tuesday\n",
    "rules_wed = association_rules(frequent_itemsets_wed, metric=\"lift\", min_threshold=1)\n",
    "#rules_wed = rules_wed[(rules_wed['lift']>=6)&rules_wed['confidence']>=0.8] #Wednesday\n",
    "rules_thu = association_rules(frequent_itemsets_thu, metric=\"lift\", min_threshold=1)\n",
    "#rules_thu = rules_thu[(rules_thu['lift']>=2)&rules_thu['confidence']>=0.8] #Thursday\n",
    "rules_fri = association_rules(frequent_itemsets_fri, metric=\"lift\", min_threshold=1)\n",
    "#rules_fri = rules_fri[(rules_fri['lift']>=5)&rules_fri['confidence']>=0.8] #Friday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6CoBKPSikhV"
   },
   "source": [
    "# Notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "IX4e6swuikhV"
   },
   "outputs": [],
   "source": [
    "def Lineconfig(command):\n",
    "\turl = 'https://notify-api.line.me/api/notify'\n",
    "\ttoken = 'UxXrixSEklJrwcl2uswmPxpOS0mlqV8YE28Q9ZtxbRZ' ## EDIT\n",
    "\theader = {'content-type':'application/x-www-form-urlencoded','Authorization':'Bearer '+token}\n",
    "\treturn requests.post(url, headers=header, data = command)\n",
    "\n",
    "def sendtext(message):\n",
    "\t# send plain text to line\n",
    "\tcommand = {'message':message}\n",
    "\treturn Lineconfig(command)\n",
    "\n",
    "def sendcon(condition):\n",
    "\t# send condition\n",
    "\tcommand = {'message':condition}\n",
    "\treturn Lineconfig(command)\n",
    "\n",
    "def sendplace(place):\n",
    "\t# send place\n",
    "\tcommand = {'message':place}\n",
    "\treturn Lineconfig(command)\n",
    "\n",
    "def sticker(sticker_id,package_id,message=' '):\n",
    "\tcommand = {'message':message,'stickerPackageId':package_id,'stickerId':sticker_id}\n",
    "\treturn Lineconfig(command)\n",
    "\n",
    "def sendnews(news):\n",
    "\t# send news\n",
    "\tcommand = {'message':news}\n",
    "\treturn Lineconfig(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "T0v2xY-VikhY"
   },
   "outputs": [],
   "source": [
    "#define time(arrival time) and notify function with each day\n",
    "day = date.today().weekday()\n",
    "cur_time = datetime.now()\n",
    "\n",
    "if day == 0:\n",
    "    time = int(mon)\n",
    "    exp_times = (cur_time+timedelta(minutes = time)).strftime('%H:%M')\n",
    "    #aviod_place = [set(i)for i in rules_mon.consequents] #from a model suggestion\n",
    "elif day == 1:\n",
    "    time = int(tue)\n",
    "    exp_times = (cur_time+timedelta(minutes = time)).strftime('%H:%M')\n",
    "    #aviod_place = [set(i)for i in rules_tue.consequents]\n",
    "elif day == 2:\n",
    "    time = int(wed)\n",
    "    exp_times = (cur_time+timedelta(minutes = time)).strftime('%H:%M')\n",
    "    #aviod_place = [set(i)for i in rules_wed.consequents]\n",
    "elif day == 3:\n",
    "    time = int(thu)\n",
    "    exp_times = (cur_time+timedelta(minutes = time)).strftime('%H:%M')\n",
    "    #aviod_place = [set(i)for i in rules_thu.consequents]\n",
    "elif day == 4:\n",
    "    time = int(fri)\n",
    "    exp_times = (cur_time+timedelta(minutes = time)).strftime('%H:%M')\n",
    "    #aviod_place = [set(i)for i in rules_fri.consequents]\n",
    "else:\n",
    "    time=\"Weekend\"\n",
    "    exp_times = \"No Observations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten list\n",
    "def flatten(l):\n",
    "    flatList = []\n",
    "    for elem in l:\n",
    "        if type(elem) == list:\n",
    "            for e in elem:\n",
    "                flatList.append(e)\n",
    "        else:\n",
    "            flatList.append(elem)\n",
    "    return flatList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Construct list of condition, place, avoid_place(no duplicate)\n",
    "condition_ls = [] #df.condition\n",
    "place_ls = [] #df.place\n",
    "for num in range(0,len(df.condition)):\n",
    "    for txt in df.condition.iloc[num]:\n",
    "        condition_ls.append(txt)\n",
    "condition_ls = set(condition_ls)\n",
    "for num in range(0,len(df.place)):\n",
    "    for txt in df.place.iloc[num]:\n",
    "        place_ls.append(txt)\n",
    "place_ls = set(place_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'งามวงศ์วาน', 'บางเขน', 'พงศ์เพชร'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map df.place with rules_day(dataframe)\n",
    "def map_place(antecedent): #where you want to map\n",
    "    map_list =[]\n",
    "    con_list = []\n",
    "    try:\n",
    "        for text in antecedent: con_list.append(list(text))\n",
    "        con_list = flatten(con_list)\n",
    "        for txt in con_list:\n",
    "            if txt in place_ls: #compare to place in scraped news; If it is found,keep. Unless, not keep!!\n",
    "                map_list.append(txt)\n",
    "        return map_list\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,',str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frozen(obj):\n",
    "    try:\n",
    "        return frozenset(obj)\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,',str(e))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#พี่แก้ตรงblog ข้างล่างนี้นะครับถ้าอยากให้มันพิมพ์อะไร โปรแกรมผม default ไว้ตามวันจริง ลองรันเล่นๆ โดยกำหนด ตัวแปรในฟังค์ชั่นได้ครับ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "goj05VREikha"
   },
   "outputs": [],
   "source": [
    "#Execute program\n",
    "def execute_notice(full_date,time,exp_time,condition,place):\n",
    "    sticker(3,6,\"Good Morning\")\n",
    "    sendtext(\"Date : {}\".format(full_date))\n",
    "    sendtext(\"การเดินทางวันนี้ใช้เวลาประมาณ {} นาที\".format(time))\n",
    "    sendtext(\"The Journey starts at {0}, and end by {1}\".format(datetime.now().strftime('%H:%M'),exp_time))\n",
    "    sendtext(\"คุณจะถึงที่ทำงานเวลาประมาณ {}\".format(exp_time))\n",
    "    sendcon(\"การจราจรโดยรวมมีปัญหา {}\".format(condition))\n",
    "    sendplace(\"Jammed Destinations {}\".format(place))\n",
    "\n",
    "    \n",
    "    \n",
    "def execute_news(news):\n",
    "    sendnews(\"สำหรับข่าวเพิ่มเติม {}\".format(news))\n",
    "\n",
    "def asso_rule(days):\n",
    "    if days ==0:\n",
    "        try:\n",
    "            #Unfrozen set type\n",
    "            list_add = []\n",
    "            for i in rules_mon.antecedents.values:\n",
    "                list_add.append(list(i))\n",
    "            list_add=flatten(list_add)\n",
    "            #Replace values\n",
    "            rules_mon[\"antecedents2\"]=list_add\n",
    "            # selecting rows based on condition \n",
    "            rslt_df = rules_mon[rules_mon.antecedents2.isin(map_place(rules_mon.antecedents))] \n",
    "            rslt_df = rslt_df[['antecedents','consequents']]\n",
    "            print_cons = [(list(plc)) for plc in rslt_df.consequents.values]\n",
    "            print_cons = set(flatten(print_cons))\n",
    "            sendtext(\"Possible traffic congession contains {}\".format(print_cons))\n",
    "            #sendtext(\"See statistical numbers \\n{}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    elif days ==1:\n",
    "        try:\n",
    "            #Unfrozen set type\n",
    "            list_add = []\n",
    "            for i in rules_tue.antecedents.values:\n",
    "                list_add.append(list(i))\n",
    "            list_add=flatten(list_add)\n",
    "            #Replace values\n",
    "            rules_tue[\"antecedents2\"]=list_add\n",
    "            # selecting rows based on condition \n",
    "            rslt_df = rules_tue[rules_tue.antecedents2.isin(map_place(rules_tue.antecedents))] \n",
    "            rslt_df = rslt_df[['antecedents','consequents']]\n",
    "            print_cons = [(list(plc)) for plc in rslt_df.consequents.values]\n",
    "            print_cons = set(flatten(print_cons))\n",
    "            sendtext(\"Possible traffic congession contains {}\".format(print_cons))\n",
    "            #sendtext(\"See statistical numbers\\n {}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    elif days ==2:\n",
    "        try:\n",
    "            #Unfrozen set type\n",
    "            list_add = []\n",
    "            for i in rules_wed.antecedents.values:\n",
    "                list_add.append(list(i))\n",
    "            list_add=flatten(list_add)\n",
    "            #Replace values\n",
    "            rules_wed[\"antecedents2\"]=list_add\n",
    "            # selecting rows based on condition \n",
    "            rslt_df = rules_wed[rules_wed.antecedents2.isin(map_place(rules_wed.antecedents))] \n",
    "            rslt_df = rslt_df[['antecedents','consequents']]\n",
    "            print_cons = [(list(plc)) for plc in rslt_df.consequents.values]\n",
    "            print_cons = set(flatten(print_cons))\n",
    "            sendtext(\"Possible traffic congession contains {}\".format(print_cons))\n",
    "            #sendtext(\"See statistical numbers\\n {}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    elif days ==3:\n",
    "        try:\n",
    "            #Unfrozen set type\n",
    "            list_add = []\n",
    "            for i in rules_thu.antecedents.values:\n",
    "                list_add.append(list(i))\n",
    "            list_add=flatten(list_add)\n",
    "            #Replace values\n",
    "            rules_thu[\"antecedents2\"]=list_add\n",
    "            # selecting rows based on condition \n",
    "            rslt_df = rules_thu[rules_thu.antecedents2.isin(map_place(rules_thu.antecedents))] \n",
    "            rslt_df = rslt_df[['antecedents','consequents']]\n",
    "            print_cons = [(list(plc)) for plc in rslt_df.consequents.values]\n",
    "            print_cons = set(flatten(print_cons))\n",
    "            sendtext(\"Possible traffic congession contains {}\".format(print_cons))\n",
    "            #sendtext(\"See statistical numbers\\n {}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    elif days ==4:\n",
    "        try:\n",
    "            #Unfrozen set type\n",
    "            list_add = []\n",
    "            for i in rules_fri.antecedents.values:\n",
    "                list_add.append(list(i))\n",
    "            list_add=flatten(list_add)\n",
    "            #Replace values\n",
    "            rules_fri[\"antecedents2\"]=list_add\n",
    "            # selecting rows based on condition \n",
    "            rslt_df = rules_fri[rules_fri.antecedents2.isin(map_place(rules_fri.antecedents))] \n",
    "            rslt_df = rslt_df[['antecedents','consequents']]\n",
    "            print_cons = [(list(plc)) for plc in rslt_df.consequents.values]\n",
    "            print_cons = set(flatten(print_cons))\n",
    "            sendtext(\"Possible traffic congession contains {}\".format(print_cons))\n",
    "            #sendtext(\"See statistical numbers\\n {}\".format(test2))\n",
    "        except BaseException as e:\n",
    "            print('failed on_status,',str(e))\n",
    "            sendtext(\"No Relevant data Today!!\")\n",
    "    else:\n",
    "        sendtext(\"Weekend: No Observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "Dv-Q3AN6ikhc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "execute_notice(full_dates,time,exp_times,condition_ls,place_ls)\n",
    "\n",
    "for i in range(0,1): # 1 latest news\n",
    "    execute_news(news=df.tweet.iloc[i])\n",
    "    \n",
    "asso_rule(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "asso_rule(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['วิภาวดี', 'เกษตร', 'เกษตร', 'เกษตร', 'เกษตร', 'เกษตร', 'เกษตร']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_place(rules_thu.antecedents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Monday = 0, Sunday =6\n",
    "sendtext(\"See possible place statistical numbers\\n{0}\\n{1}\\n{2}\\n{3}\".format(test2.columns, test2.antecedents.values,test2.consequents.values,test2.confidence.values,test2.lift.values))\n",
    "def asso_rule(days):\n",
    "    if days ==1:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_mon['antecedents'] == frozenset(map_place(rules_mon.antecedents))]\n",
    "        #grap all consequents\n",
    "        con_place = []\n",
    "        for pla in test.consequents:\n",
    "            con_place.append(list(pla))\n",
    "            con_place= set(flatten(con_place))\n",
    "        sendtext(\"Possible jammed places {}\".format(con_place))\n",
    "        test2 = test[['consequents','confidence','lift']]\n",
    "        sendtext(\"See statistical numbers {}\".format(test2))\n",
    "    elif days ==2:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_tue['antecedents'] == frozenset(map_place(rules_tue.antecedents))]\n",
    "        #grap all consequents\n",
    "        con_place = []\n",
    "        for pla in test.consequents:\n",
    "            con_place.append(list(pla))\n",
    "            con_place= set(flatten(con_place))\n",
    "        sendtext(\"Possible jammed places {}\".format(con_place))\n",
    "        test2 = test[['consequents','confidence','lift']]\n",
    "        sendtext(\"See statistical numbers {}\".format(test2))\n",
    "    elif days ==3:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_wed['antecedents'] == frozenset(map_place(rules_wed.antecedents))]\n",
    "        #grap all consequents\n",
    "        con_place = []\n",
    "        for pla in test.consequents:\n",
    "            con_place.append(list(pla))\n",
    "            con_place= set(flatten(con_place))\n",
    "        sendtext(\"Possible jammed places {}\".format(con_place))\n",
    "        test2 = test[['consequents','confidence','lift']]\n",
    "        sendtext(\"See statistical numbers {}\".format(test2))\n",
    "    elif days ==4:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_thu['antecedents'] == frozenset(map_place(rules_thu.antecedents))]\n",
    "        #grap all consequents\n",
    "        #result_place = list()\n",
    "        #for pla in test.consequents:\n",
    "         #   result_place.append(pla)\n",
    "          #  result_place= set(flatten(result_place))\n",
    "        #sendtext(\"Possible jammed places {}\".format(result_place))\n",
    "        #test2 = test[['consequents','confidence','lift']]\n",
    "        sendtext(\"See statistical numbers {}\".format(test))\n",
    "    elif days ==5:\n",
    "        #show consequences\n",
    "        test=rules_thu[rules_fri['antecedents'] == frozenset(map_place(rules_fri.antecedents))]\n",
    "        #grap all consequents\n",
    "        con_place = []\n",
    "        for pla in test.consequents:\n",
    "            con_place.append(list(pla))\n",
    "            con_place= set(flatten(con_place))\n",
    "        sendtext(\"Possible jammed places {}\".format(con_place))\n",
    "        sendtext(\"See statistical numbers {}\".format(test2))\n",
    "    else:\n",
    "        sendtext(\"Weekend\")\n",
    "        \n",
    "        \n",
    "        #Not able to use\n",
    "aviod_place = [set(i)for i in rules_fri.consequents]\n",
    "aviod_place\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Full Al.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
